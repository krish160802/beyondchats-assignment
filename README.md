# BeyondChats â€“ Full Stack Web Developer Assignment

This repository contains my submission for the **BeyondChats Full Stack Web Developer Intern assignment**, implementing blog scraping, REST APIs, AI-powered article updates, and a React-based frontend.

---

## ğŸš€ Live Project Links

- **Frontend (React App)**  
  ğŸ‘‰ [https://YOUR_FRONTEND_URL.vercel.app](https://beyondchats-assignment-sigma.vercel.app/)  

- **Backend API**  
  ğŸ‘‰ https://beyondchats-assignment-0nfm.onrender.com/api/articles  

The frontend displays both **original articles** and their **AI-updated versions** along with references.

---

## âš™ï¸ Local Setup Instructions

### ğŸ”¹ Prerequisites
- Node.js (v18+ recommended)
- npm


### ğŸ”¹ Backend Setup

```bash
cd backend
npm install
node db/setup.js
npm run dev

Backend runs at:
http://localhost:3000
```

### ğŸ”¹ Scripts to run

```bash
cd backend
node scraper/scrapeBeyondChats.js

cd backend
node scripts/updateArticles.js
```

### ğŸ”¹ Frontend Setup

```bash
cd frontend
npm install
npm run dev

Frontend runs at:
http://localhost:5173
```
---

## ğŸ§  Data Flow / Architecture Diagram

```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BeyondChats Blogs â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Puppeteer Scraping
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SQLite Database   â”‚
â”‚ (Original Articles)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ REST APIs (CRUD)
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node.js + Express â”‚
â”‚  Backend APIs      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ Automation
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Google Search (SerpAPI)              â”‚
â”‚ + External Article Scraping          â”‚
â”‚ + Groq LLM (Article Rewrite)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Post Api publishing an updated article
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SQLite Database    â”‚
â”‚ (Updated Articles) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Axios to display
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend    â”‚
â”‚  (Vite + UI)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Summary

### ğŸ”¹ Phase 1 â€“ Blog Scraping & APIs
- Scraped the oldest available articles from BeyondChats blogs using Puppeteer
- Filtered pagination and tag pages
- Extracted clean article content (excluding comments and metadata)
- Stored articles in SQLite
- Built full CRUD APIs using Express.js

Running Scraping Script (Phase 1)
```bash
cd backend
node scraper/scrapeBeyondChats.js
```
  

### ğŸ”¹ Phase 2 â€“ AI Article Update Automation
- Fetches original articles via backend API
- Searches the article title on Google using SerpAPI
- Fetches the top 2 external blog/article links
- Scrapes main content from these external articles
- Uses Groq LLM to rewrite the original article to match the style and structure of higher-ranking content
- Publishes the updated article via backend APIs
- Stores reference URLs for citation transparency

Running Automation Script (Phase 2)
```bash
cd backend
node scripts/updateArticles.js
```

### âš ï¸ Controlled Execution (Important)
#### Only ONE article is processed per execution due to :
- This behavior is intentional and implemented to prevent excessive LLM API usage.
- This can be easily extended to batch processing if required.



### ğŸ”¹ Phase 3 â€“ Frontend (React)

- Built with React + Vite
- Displays Original articles and AI-updated articles
- Graceful loading and empty states and responsive layout

---

## ğŸ§© Notes
- SQLite is file-based; production deployments start with an empty database.
- Articles can be populated by running scraping or automation scripts.
- Some very old archived blog posts not exposed in the blog feed are intentionally excluded.

---
## ğŸ‘¤ Author
### Krish Khera

